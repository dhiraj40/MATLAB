
 %%%%%%%%%%%%%%%%%%%%%  Layers specification %%%%%%%%%%%%%%%%%%
 
 	net.layers{end+1}.properties = struct('type','input', 'sizeFm' ,[24],'numFm',1 );         %inputLayer

 	net.layers{end+1}.properties = struct('type','conv','numFm',12,'kernel',5);
 	net.layers{end+1}.properties = struct('type','fc','numFm',128);
 	net.layers{end+1}.properties = struct('type','fc','numFm',16);
 	net.layers{end+1}.properties = struct('type','softmax');
  	net.layers{end+1}.properties = struct('type','output','lossFunc',@CrossEnt,'costFunc',@CrossEnt_Cost);     %output Layer - classification 
	
 %%%%%%%%%%%%%%%%%%%%%  Hyper params - training %%%%%%%%%%%%%%%%%%
 
 	net.hyperParam.trainLoopCount = 4000;		%on how many images to train before evaluating the network
 	net.hyperParam.testImageNum   = 400;   	% after each loop, on how many images to evaluate network performance
 	net.hyperParam.ni_initial     = 0.001;		% ni to start training process
    net.hyperParam.momentum       = 0.9;

 	net.hyperParam.ni_final       = 0.0005;	        % final ni to stop the training process
    net.hyperParam.normalizeNetworkInput = 0;
	net.hyperParam.batchNum=10;
 
