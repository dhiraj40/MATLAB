 %  reach 99.24% on MNIST. 
 %  Training finish after about 446 iteration , (37 epocs) can be reduces with some tweaks

 %%%%%%%%%%%%%%%%%%%%%  input settings  %%%%%%%%%%%%%%%%%%
  	net.layers{end+1}.properties = struct('type','input', 'sizeFm' ,[28 28],'numFm',1 );         %inputLayer
 	net.layers{end+1}.properties = struct('type','conv','numFm',7  ,'kernel',5,'pad',2);
 	net.layers{end+1}.properties = struct('type','conv','numFm',17 ,'kernel',13);
 	net.layers{end+1}.properties = struct('type','fc','numFm',127);
 	net.layers{end+1}.properties = struct('type','fc','numFm',10);
	net.layers{end+1}.properties = struct('type','output','lossFunc',@CrossEnt,'costFunc',@CrossEnt_Cost);     %output Layer

 
 %%%%%%%%%%%%%%%%%%%%%  Hyper params - training %%%%%%%%%%%%%%%%%%
 
 	net.hyperParam.trainLoopCount = 5000;		%on how many images to train before evaluating the network
 	net.hyperParam.testImageNum   = 10000;   	% after each loop, on how many images to evaluate network performance
 	net.hyperParam.ni_initial     = 0.05;		% ni to start training process
 	net.hyperParam.ni_final       = 0.00001;	% final ni to stop the training process
 
 
